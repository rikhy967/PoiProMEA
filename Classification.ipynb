{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data after PP/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          mu1      lam1           mu2     sigma       mu3    sigma3        w1  \\\n0    0.099999  0.010000  1.376800e-01  0.069408  0.368091  0.172628  0.286221   \n1    0.019293  0.019831  6.633874e-02  0.000100  0.100001  0.000520  1.000000   \n2    0.043575  0.029764  1.779872e-01  0.000100  0.100064  0.000260  1.000000   \n3    0.024164  0.022119  6.418069e-02  0.000100  0.100010  0.000718  1.000000   \n4    0.048184  0.030814  4.696582e-03  0.000100  0.100139  0.000218  1.000000   \n..        ...       ...           ...       ...       ...       ...       ...   \n543  0.100000  0.011880  1.038845e-01  0.058294  0.483309  0.271518  0.332834   \n544  0.018542  0.018771  1.807094e-01  0.000100  0.100000  0.000106  1.000000   \n545  0.099969  0.039687  9.343772e-02  0.040354  0.267501  0.112234  0.630343   \n546  0.056240  0.031443  1.643654e-07  0.000100  0.100001  0.000100  1.000000   \n547  0.100000  0.040000  1.008357e-01  0.044780  0.403570  0.174828  0.774085   \n\n               w2            w3  n_spikes  Target  \n0    4.179009e-01  2.958779e-01    1015.0     0.0  \n1    1.192093e-07  1.421085e-14   10364.0     0.0  \n2    1.192093e-07  1.421085e-14    4589.0     0.0  \n3    1.192093e-07  1.421085e-14    8274.0     0.0  \n4    1.192093e-07  1.421085e-14    4151.0     0.0  \n..            ...           ...       ...     ...  \n543  4.549999e-01  2.121657e-01    1029.0     1.0  \n544  1.192093e-07  1.421085e-14   10784.0     1.0  \n545  2.080073e-01  1.616492e-01    1523.0     1.0  \n546  1.192093e-07  1.421085e-14    3555.0     1.0  \n547  1.422010e-01  8.371432e-02    1475.0     1.0  \n\n[548 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mu1</th>\n      <th>lam1</th>\n      <th>mu2</th>\n      <th>sigma</th>\n      <th>mu3</th>\n      <th>sigma3</th>\n      <th>w1</th>\n      <th>w2</th>\n      <th>w3</th>\n      <th>n_spikes</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.099999</td>\n      <td>0.010000</td>\n      <td>1.376800e-01</td>\n      <td>0.069408</td>\n      <td>0.368091</td>\n      <td>0.172628</td>\n      <td>0.286221</td>\n      <td>4.179009e-01</td>\n      <td>2.958779e-01</td>\n      <td>1015.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.019293</td>\n      <td>0.019831</td>\n      <td>6.633874e-02</td>\n      <td>0.000100</td>\n      <td>0.100001</td>\n      <td>0.000520</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>10364.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.043575</td>\n      <td>0.029764</td>\n      <td>1.779872e-01</td>\n      <td>0.000100</td>\n      <td>0.100064</td>\n      <td>0.000260</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>4589.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.024164</td>\n      <td>0.022119</td>\n      <td>6.418069e-02</td>\n      <td>0.000100</td>\n      <td>0.100010</td>\n      <td>0.000718</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>8274.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.048184</td>\n      <td>0.030814</td>\n      <td>4.696582e-03</td>\n      <td>0.000100</td>\n      <td>0.100139</td>\n      <td>0.000218</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>4151.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>0.100000</td>\n      <td>0.011880</td>\n      <td>1.038845e-01</td>\n      <td>0.058294</td>\n      <td>0.483309</td>\n      <td>0.271518</td>\n      <td>0.332834</td>\n      <td>4.549999e-01</td>\n      <td>2.121657e-01</td>\n      <td>1029.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>0.018542</td>\n      <td>0.018771</td>\n      <td>1.807094e-01</td>\n      <td>0.000100</td>\n      <td>0.100000</td>\n      <td>0.000106</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>10784.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>545</th>\n      <td>0.099969</td>\n      <td>0.039687</td>\n      <td>9.343772e-02</td>\n      <td>0.040354</td>\n      <td>0.267501</td>\n      <td>0.112234</td>\n      <td>0.630343</td>\n      <td>2.080073e-01</td>\n      <td>1.616492e-01</td>\n      <td>1523.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>0.056240</td>\n      <td>0.031443</td>\n      <td>1.643654e-07</td>\n      <td>0.000100</td>\n      <td>0.100001</td>\n      <td>0.000100</td>\n      <td>1.000000</td>\n      <td>1.192093e-07</td>\n      <td>1.421085e-14</td>\n      <td>3555.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>0.100000</td>\n      <td>0.040000</td>\n      <td>1.008357e-01</td>\n      <td>0.044780</td>\n      <td>0.403570</td>\n      <td>0.174828</td>\n      <td>0.774085</td>\n      <td>1.422010e-01</td>\n      <td>8.371432e-02</td>\n      <td>1475.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>548 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.0    317\n1.0    231\nName: Target, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['Target'],axis=1)\n",
    "y= dataset['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':np.linspace(2,10,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found : {'criterion': 'entropy', 'max_depth': 4} \n",
      "\n",
      "Classification report on Test set\n",
      "\n",
      "Accuracy:  0.912\n",
      "Recall:  0.931\n",
      "Precision:  0.871\n",
      "ROC AUC:  0.915\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':np.logspace(-3,3,50),'penalty':['l1','l2','elasticnet']}\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear',random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found : {'C': 0.21209508879201905, 'penalty': 'l1'} \n",
      "\n",
      "Classification report on Test set\n",
      "\n",
      "Accuracy:  0.825\n",
      "Recall:  0.655\n",
      "Precision:  0.905\n",
      "ROC AUC:  0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':np.logspace(-3,3,50),'kernel':['linear','rbf']}\n",
    "\n",
    "clf = SVC(random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found : {'C': 8.286427728546842, 'kernel': 'rbf'} \n",
      "\n",
      "Classification report on Test set\n",
      "\n",
      "Accuracy:  0.927\n",
      "Recall:  0.931\n",
      "Precision:  0.9\n",
      "ROC AUC:  0.928\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1000 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1401s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0004s.) Setting batch_size=4.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\", line 306, in _score\n    y_pred = method_caller(clf, \"decision_function\", X)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\", line 52, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\nAttributeError: 'RandomForestClassifier' object has no attribute 'decision_function'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\", line 797, in dispatch_one_batch\n    tasks = self._ready_batches.get(block=False)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/queue.py\", line 161, in get\n    raise Empty\nqueue.Empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 544, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 591, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n    *args, **kwargs)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\", line 313, in _score\n    y_pred = method_caller(clf, \"predict_proba\", X)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\", line 52, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\", line 669, in predict_proba\n    for e in self.estimators_)\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\", line 1004, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\", line 808, in dispatch_one_batch\n    islice = list(itertools.islice(iterator, big_batch_size))\nValueError: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-10ddd9d52a0b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'roc_auc'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcv\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mgs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    708\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    709\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 710\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    711\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    712\u001B[0m         \u001B[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1150\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1151\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params)\u001B[0m\n\u001B[1;32m    687\u001B[0m                                \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m                                in product(candidate_params,\n\u001B[0;32m--> 689\u001B[0;31m                                           cv.split(X, y, groups)))\n\u001B[0m\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1015\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1016\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1017\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1018\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1019\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    907\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    908\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 909\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    910\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    911\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    560\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    561\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 562\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    563\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mLokyTimeoutError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    564\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    430\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    431\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 432\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    433\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/Neuro/lib/python3.6/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 384\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    385\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    386\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize."
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':np.linspace(10,150,dtype='int',num=10),'max_depth':np.linspace(2,5,dtype='int'),'criterion':['gini','entropy']}\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1,random_state=12)\n",
    "\n",
    "gs = GridSearchCV(clf, params, scoring='roc_auc',cv=cv,verbose=10,n_jobs=-1)\n",
    "\n",
    "gs=gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found :\",gs.best_params_,'\\n')\n",
    "print(\"Classification report on Test set\\n\")\n",
    "\n",
    "y_true, y_pred = y_test, gs.predict(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(411, 10)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-293466891f45>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,421\n",
      "Trainable params: 7,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            20, activation=\"relu\", input_shape=(X_train.shape[1],)\n",
    "        ),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 411 samples, validate on 137 samples\n",
      "WARNING:tensorflow:From /Users/rikhy96/opt/anaconda3/envs/Neuro/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "411/411 [==============================] - 1s 2ms/sample - loss: 0.5677 - acc: 0.7348 - fn: 60.0000 - fp: 49.0000 - tn: 189.0000 - tp: 113.0000 - precision: 0.6975 - recall: 0.6532 - val_loss: 0.4216 - val_acc: 0.8540 - val_fn: 13.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 45.0000 - val_precision: 0.8654 - val_recall: 0.7759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.4019 - acc: 0.8540 - fn: 32.0000 - fp: 28.0000 - tn: 210.0000 - tp: 141.0000 - precision: 0.8343 - recall: 0.8150 - val_loss: 0.4029 - val_acc: 0.8248 - val_fn: 8.0000 - val_fp: 16.0000 - val_tn: 63.0000 - val_tp: 50.0000 - val_precision: 0.7576 - val_recall: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.4354 - acc: 0.8418 - fn: 30.0000 - fp: 35.0000 - tn: 203.0000 - tp: 143.0000 - precision: 0.8034 - recall: 0.8266 - val_loss: 0.3349 - val_acc: 0.8832 - val_fn: 10.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 48.0000 - val_precision: 0.8889 - val_recall: 0.8276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/200\n",
      "411/411 [==============================] - 0s 240us/sample - loss: 0.3592 - acc: 0.8540 - fn: 30.0000 - fp: 30.0000 - tn: 208.0000 - tp: 143.0000 - precision: 0.8266 - recall: 0.8266 - val_loss: 0.2987 - val_acc: 0.8832 - val_fn: 8.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 50.0000 - val_precision: 0.8621 - val_recall: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.3371 - acc: 0.8905 - fn: 20.0000 - fp: 25.0000 - tn: 213.0000 - tp: 153.0000 - precision: 0.8596 - recall: 0.8844 - val_loss: 0.2549 - val_acc: 0.8978 - val_fn: 7.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 51.0000 - val_precision: 0.8793 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.3170 - acc: 0.8954 - fn: 26.0000 - fp: 17.0000 - tn: 221.0000 - tp: 147.0000 - precision: 0.8963 - recall: 0.8497 - val_loss: 0.2851 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/200\n",
      "411/411 [==============================] - 0s 264us/sample - loss: 0.3001 - acc: 0.8735 - fn: 25.0000 - fp: 27.0000 - tn: 211.0000 - tp: 148.0000 - precision: 0.8457 - recall: 0.8555 - val_loss: 0.4645 - val_acc: 0.7445 - val_fn: 0.0000e+00 - val_fp: 35.0000 - val_tn: 44.0000 - val_tp: 58.0000 - val_precision: 0.6237 - val_recall: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/200\n",
      "411/411 [==============================] - 0s 238us/sample - loss: 0.3304 - acc: 0.8735 - fn: 22.0000 - fp: 30.0000 - tn: 208.0000 - tp: 151.0000 - precision: 0.8343 - recall: 0.8728 - val_loss: 0.2598 - val_acc: 0.8905 - val_fn: 8.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 50.0000 - val_precision: 0.8772 - val_recall: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/200\n",
      "411/411 [==============================] - 0s 258us/sample - loss: 0.2793 - acc: 0.9027 - fn: 18.0000 - fp: 22.0000 - tn: 216.0000 - tp: 155.0000 - precision: 0.8757 - recall: 0.8960 - val_loss: 0.2768 - val_acc: 0.8832 - val_fn: 13.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 45.0000 - val_precision: 0.9375 - val_recall: 0.7759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2518 - acc: 0.9124 - fn: 20.0000 - fp: 16.0000 - tn: 222.0000 - tp: 153.0000 - precision: 0.9053 - recall: 0.8844 - val_loss: 0.1915 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2884 - acc: 0.8905 - fn: 19.0000 - fp: 26.0000 - tn: 212.0000 - tp: 154.0000 - precision: 0.8556 - recall: 0.8902 - val_loss: 0.2293 - val_acc: 0.9124 - val_fn: 8.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 50.0000 - val_precision: 0.9259 - val_recall: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/200\n",
      "411/411 [==============================] - 0s 240us/sample - loss: 0.2441 - acc: 0.9027 - fn: 17.0000 - fp: 23.0000 - tn: 215.0000 - tp: 156.0000 - precision: 0.8715 - recall: 0.9017 - val_loss: 0.1728 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2336 - acc: 0.9124 - fn: 14.0000 - fp: 22.0000 - tn: 216.0000 - tp: 159.0000 - precision: 0.8785 - recall: 0.9191 - val_loss: 0.1969 - val_acc: 0.9197 - val_fn: 3.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 55.0000 - val_precision: 0.8730 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.2811 - acc: 0.8929 - fn: 26.0000 - fp: 18.0000 - tn: 220.0000 - tp: 147.0000 - precision: 0.8909 - recall: 0.8497 - val_loss: 0.2309 - val_acc: 0.8905 - val_fn: 8.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 50.0000 - val_precision: 0.8772 - val_recall: 0.8621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/200\n",
      "411/411 [==============================] - 0s 243us/sample - loss: 0.2432 - acc: 0.8954 - fn: 24.0000 - fp: 19.0000 - tn: 219.0000 - tp: 149.0000 - precision: 0.8869 - recall: 0.8613 - val_loss: 0.2430 - val_acc: 0.8905 - val_fn: 4.0000 - val_fp: 11.0000 - val_tn: 68.0000 - val_tp: 54.0000 - val_precision: 0.8308 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.2454 - acc: 0.8832 - fn: 17.0000 - fp: 31.0000 - tn: 207.0000 - tp: 156.0000 - precision: 0.8342 - recall: 0.9017 - val_loss: 0.2105 - val_acc: 0.9124 - val_fn: 5.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 53.0000 - val_precision: 0.8833 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.2281 - acc: 0.9173 - fn: 16.0000 - fp: 18.0000 - tn: 220.0000 - tp: 157.0000 - precision: 0.8971 - recall: 0.9075 - val_loss: 0.1834 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.2470 - acc: 0.9100 - fn: 19.0000 - fp: 18.0000 - tn: 220.0000 - tp: 154.0000 - precision: 0.8953 - recall: 0.8902 - val_loss: 0.1900 - val_acc: 0.9197 - val_fn: 6.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 52.0000 - val_precision: 0.9123 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/200\n",
      "411/411 [==============================] - 0s 237us/sample - loss: 0.2047 - acc: 0.9173 - fn: 17.0000 - fp: 17.0000 - tn: 221.0000 - tp: 156.0000 - precision: 0.9017 - recall: 0.9017 - val_loss: 0.2084 - val_acc: 0.9197 - val_fn: 5.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 53.0000 - val_precision: 0.8983 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.2410 - acc: 0.9027 - fn: 21.0000 - fp: 19.0000 - tn: 219.0000 - tp: 152.0000 - precision: 0.8889 - recall: 0.8786 - val_loss: 0.2095 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2788 - acc: 0.8832 - fn: 25.0000 - fp: 23.0000 - tn: 215.0000 - tp: 148.0000 - precision: 0.8655 - recall: 0.8555 - val_loss: 0.2935 - val_acc: 0.8832 - val_fn: 7.0000 - val_fp: 9.0000 - val_tn: 70.0000 - val_tp: 51.0000 - val_precision: 0.8500 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/200\n",
      "411/411 [==============================] - 0s 240us/sample - loss: 0.2673 - acc: 0.8978 - fn: 21.0000 - fp: 21.0000 - tn: 217.0000 - tp: 152.0000 - precision: 0.8786 - recall: 0.8786 - val_loss: 0.1823 - val_acc: 0.9270 - val_fn: 6.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 52.0000 - val_precision: 0.9286 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/200\n",
      "411/411 [==============================] - 0s 240us/sample - loss: 0.2198 - acc: 0.9197 - fn: 19.0000 - fp: 14.0000 - tn: 224.0000 - tp: 154.0000 - precision: 0.9167 - recall: 0.8902 - val_loss: 0.1827 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.2393 - acc: 0.9002 - fn: 24.0000 - fp: 17.0000 - tn: 221.0000 - tp: 149.0000 - precision: 0.8976 - recall: 0.8613 - val_loss: 0.1863 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1994 - acc: 0.9270 - fn: 15.0000 - fp: 15.0000 - tn: 223.0000 - tp: 158.0000 - precision: 0.9133 - recall: 0.9133 - val_loss: 0.2123 - val_acc: 0.9124 - val_fn: 5.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 53.0000 - val_precision: 0.8833 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.3378 - acc: 0.8881 - fn: 24.0000 - fp: 22.0000 - tn: 216.0000 - tp: 149.0000 - precision: 0.8713 - recall: 0.8613 - val_loss: 0.2593 - val_acc: 0.9197 - val_fn: 5.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 53.0000 - val_precision: 0.8983 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/200\n",
      "411/411 [==============================] - 0s 240us/sample - loss: 0.2440 - acc: 0.9075 - fn: 23.0000 - fp: 15.0000 - tn: 223.0000 - tp: 150.0000 - precision: 0.9091 - recall: 0.8671 - val_loss: 0.1988 - val_acc: 0.9197 - val_fn: 5.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 53.0000 - val_precision: 0.8983 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2268 - acc: 0.8978 - fn: 23.0000 - fp: 19.0000 - tn: 219.0000 - tp: 150.0000 - precision: 0.8876 - recall: 0.8671 - val_loss: 0.2292 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.2161 - acc: 0.9100 - fn: 19.0000 - fp: 18.0000 - tn: 220.0000 - tp: 154.0000 - precision: 0.8953 - recall: 0.8902 - val_loss: 0.2227 - val_acc: 0.9124 - val_fn: 3.0000 - val_fp: 9.0000 - val_tn: 70.0000 - val_tp: 55.0000 - val_precision: 0.8594 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1952 - acc: 0.9343 - fn: 12.0000 - fp: 15.0000 - tn: 223.0000 - tp: 161.0000 - precision: 0.9148 - recall: 0.9306 - val_loss: 0.2053 - val_acc: 0.9343 - val_fn: 6.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 52.0000 - val_precision: 0.9455 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/200\n",
      "411/411 [==============================] - 0s 267us/sample - loss: 0.2176 - acc: 0.9173 - fn: 21.0000 - fp: 13.0000 - tn: 225.0000 - tp: 152.0000 - precision: 0.9212 - recall: 0.8786 - val_loss: 0.2057 - val_acc: 0.9197 - val_fn: 9.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 49.0000 - val_precision: 0.9608 - val_recall: 0.8448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/200\n",
      "411/411 [==============================] - 0s 243us/sample - loss: 0.2502 - acc: 0.9100 - fn: 21.0000 - fp: 16.0000 - tn: 222.0000 - tp: 152.0000 - precision: 0.9048 - recall: 0.8786 - val_loss: 0.2608 - val_acc: 0.9124 - val_fn: 4.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 54.0000 - val_precision: 0.8710 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/200\n",
      "411/411 [==============================] - 0s 254us/sample - loss: 0.2308 - acc: 0.9051 - fn: 19.0000 - fp: 20.0000 - tn: 218.0000 - tp: 154.0000 - precision: 0.8851 - recall: 0.8902 - val_loss: 0.1953 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/200\n",
      "411/411 [==============================] - 0s 243us/sample - loss: 0.2322 - acc: 0.9148 - fn: 16.0000 - fp: 19.0000 - tn: 219.0000 - tp: 157.0000 - precision: 0.8920 - recall: 0.9075 - val_loss: 0.1914 - val_acc: 0.9270 - val_fn: 2.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 56.0000 - val_precision: 0.8750 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1927 - acc: 0.9270 - fn: 12.0000 - fp: 18.0000 - tn: 220.0000 - tp: 161.0000 - precision: 0.8994 - recall: 0.9306 - val_loss: 0.1665 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1928 - acc: 0.9221 - fn: 20.0000 - fp: 12.0000 - tn: 226.0000 - tp: 153.0000 - precision: 0.9273 - recall: 0.8844 - val_loss: 0.2214 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.2042 - acc: 0.9002 - fn: 20.0000 - fp: 21.0000 - tn: 217.0000 - tp: 153.0000 - precision: 0.8793 - recall: 0.8844 - val_loss: 0.1832 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/200\n",
      "411/411 [==============================] - 0s 252us/sample - loss: 0.2292 - acc: 0.9148 - fn: 20.0000 - fp: 15.0000 - tn: 223.0000 - tp: 153.0000 - precision: 0.9107 - recall: 0.8844 - val_loss: 0.1842 - val_acc: 0.9124 - val_fn: 3.0000 - val_fp: 9.0000 - val_tn: 70.0000 - val_tp: 55.0000 - val_precision: 0.8594 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/200\n",
      "411/411 [==============================] - 0s 296us/sample - loss: 0.1926 - acc: 0.9197 - fn: 17.0000 - fp: 16.0000 - tn: 222.0000 - tp: 156.0000 - precision: 0.9070 - recall: 0.9017 - val_loss: 0.2965 - val_acc: 0.8978 - val_fn: 1.0000 - val_fp: 13.0000 - val_tn: 66.0000 - val_tp: 57.0000 - val_precision: 0.8143 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/200\n",
      "411/411 [==============================] - 0s 257us/sample - loss: 0.1984 - acc: 0.9173 - fn: 18.0000 - fp: 16.0000 - tn: 222.0000 - tp: 155.0000 - precision: 0.9064 - recall: 0.8960 - val_loss: 0.1394 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.2140 - acc: 0.9148 - fn: 17.0000 - fp: 18.0000 - tn: 220.0000 - tp: 156.0000 - precision: 0.8966 - recall: 0.9017 - val_loss: 0.1648 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1714 - acc: 0.9319 - fn: 12.0000 - fp: 16.0000 - tn: 222.0000 - tp: 161.0000 - precision: 0.9096 - recall: 0.9306 - val_loss: 0.1373 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.2002 - acc: 0.9294 - fn: 17.0000 - fp: 12.0000 - tn: 226.0000 - tp: 156.0000 - precision: 0.9286 - recall: 0.9017 - val_loss: 0.1402 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1866 - acc: 0.9221 - fn: 17.0000 - fp: 15.0000 - tn: 223.0000 - tp: 156.0000 - precision: 0.9123 - recall: 0.9017 - val_loss: 0.1815 - val_acc: 0.9270 - val_fn: 2.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 56.0000 - val_precision: 0.8750 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.1754 - acc: 0.9197 - fn: 14.0000 - fp: 19.0000 - tn: 219.0000 - tp: 159.0000 - precision: 0.8933 - recall: 0.9191 - val_loss: 0.1315 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/200\n",
      "411/411 [==============================] - 0s 255us/sample - loss: 0.1736 - acc: 0.9270 - fn: 15.0000 - fp: 15.0000 - tn: 223.0000 - tp: 158.0000 - precision: 0.9133 - recall: 0.9133 - val_loss: 0.1530 - val_acc: 0.9270 - val_fn: 7.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 51.0000 - val_precision: 0.9444 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.2030 - acc: 0.9124 - fn: 19.0000 - fp: 17.0000 - tn: 221.0000 - tp: 154.0000 - precision: 0.9006 - recall: 0.8902 - val_loss: 0.1449 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1890 - acc: 0.9197 - fn: 16.0000 - fp: 17.0000 - tn: 221.0000 - tp: 157.0000 - precision: 0.9023 - recall: 0.9075 - val_loss: 0.1834 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/200\n",
      "411/411 [==============================] - 0s 237us/sample - loss: 0.1824 - acc: 0.9367 - fn: 10.0000 - fp: 16.0000 - tn: 222.0000 - tp: 163.0000 - precision: 0.9106 - recall: 0.9422 - val_loss: 0.1477 - val_acc: 0.9270 - val_fn: 6.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 52.0000 - val_precision: 0.9286 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/200\n",
      "411/411 [==============================] - 0s 274us/sample - loss: 0.1795 - acc: 0.9392 - fn: 13.0000 - fp: 12.0000 - tn: 226.0000 - tp: 160.0000 - precision: 0.9302 - recall: 0.9249 - val_loss: 0.1816 - val_acc: 0.9562 - val_fn: 1.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 57.0000 - val_precision: 0.9194 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 51/200\n",
      "411/411 [==============================] - 0s 258us/sample - loss: 0.1896 - acc: 0.9246 - fn: 17.0000 - fp: 14.0000 - tn: 224.0000 - tp: 156.0000 - precision: 0.9176 - recall: 0.9017 - val_loss: 0.1811 - val_acc: 0.9343 - val_fn: 1.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 57.0000 - val_precision: 0.8769 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 52/200\n",
      "411/411 [==============================] - 0s 235us/sample - loss: 0.1822 - acc: 0.9197 - fn: 16.0000 - fp: 17.0000 - tn: 221.0000 - tp: 157.0000 - precision: 0.9023 - recall: 0.9075 - val_loss: 0.1513 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 53/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.1961 - acc: 0.9002 - fn: 17.0000 - fp: 24.0000 - tn: 214.0000 - tp: 156.0000 - precision: 0.8667 - recall: 0.9017 - val_loss: 0.2267 - val_acc: 0.9197 - val_fn: 5.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 53.0000 - val_precision: 0.8983 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 54/200\n",
      "411/411 [==============================] - 0s 257us/sample - loss: 0.1928 - acc: 0.9027 - fn: 16.0000 - fp: 24.0000 - tn: 214.0000 - tp: 157.0000 - precision: 0.8674 - recall: 0.9075 - val_loss: 0.1525 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 55/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1522 - acc: 0.9416 - fn: 9.0000 - fp: 15.0000 - tn: 223.0000 - tp: 164.0000 - precision: 0.9162 - recall: 0.9480 - val_loss: 0.1446 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 56/200\n",
      "411/411 [==============================] - 0s 255us/sample - loss: 0.1601 - acc: 0.9319 - fn: 14.0000 - fp: 14.0000 - tn: 224.0000 - tp: 159.0000 - precision: 0.9191 - recall: 0.9191 - val_loss: 0.1587 - val_acc: 0.9270 - val_fn: 2.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 56.0000 - val_precision: 0.8750 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 57/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2086 - acc: 0.9246 - fn: 12.0000 - fp: 19.0000 - tn: 219.0000 - tp: 161.0000 - precision: 0.8944 - recall: 0.9306 - val_loss: 0.2006 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 58/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.1712 - acc: 0.9270 - fn: 13.0000 - fp: 17.0000 - tn: 221.0000 - tp: 160.0000 - precision: 0.9040 - recall: 0.9249 - val_loss: 0.1912 - val_acc: 0.9343 - val_fn: 2.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 56.0000 - val_precision: 0.8889 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 59/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1634 - acc: 0.9392 - fn: 8.0000 - fp: 17.0000 - tn: 221.0000 - tp: 165.0000 - precision: 0.9066 - recall: 0.9538 - val_loss: 0.1679 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 60/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1540 - acc: 0.9440 - fn: 10.0000 - fp: 13.0000 - tn: 225.0000 - tp: 163.0000 - precision: 0.9261 - recall: 0.9422 - val_loss: 0.1976 - val_acc: 0.9416 - val_fn: 6.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 52.0000 - val_precision: 0.9630 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 61/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.2269 - acc: 0.9197 - fn: 16.0000 - fp: 17.0000 - tn: 221.0000 - tp: 157.0000 - precision: 0.9023 - recall: 0.9075 - val_loss: 0.1534 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 62/200\n",
      "411/411 [==============================] - 0s 252us/sample - loss: 0.1648 - acc: 0.9319 - fn: 15.0000 - fp: 13.0000 - tn: 225.0000 - tp: 158.0000 - precision: 0.9240 - recall: 0.9133 - val_loss: 0.1431 - val_acc: 0.9562 - val_fn: 4.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 54.0000 - val_precision: 0.9643 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 63/200\n",
      "411/411 [==============================] - 0s 280us/sample - loss: 0.1784 - acc: 0.9392 - fn: 15.0000 - fp: 10.0000 - tn: 228.0000 - tp: 158.0000 - precision: 0.9405 - recall: 0.9133 - val_loss: 0.2401 - val_acc: 0.9343 - val_fn: 6.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 52.0000 - val_precision: 0.9455 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 64/200\n",
      "411/411 [==============================] - 0s 265us/sample - loss: 0.2124 - acc: 0.9270 - fn: 13.0000 - fp: 17.0000 - tn: 221.0000 - tp: 160.0000 - precision: 0.9040 - recall: 0.9249 - val_loss: 0.2917 - val_acc: 0.9124 - val_fn: 3.0000 - val_fp: 9.0000 - val_tn: 70.0000 - val_tp: 55.0000 - val_precision: 0.8594 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 65/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.2188 - acc: 0.9148 - fn: 18.0000 - fp: 17.0000 - tn: 221.0000 - tp: 155.0000 - precision: 0.9012 - recall: 0.8960 - val_loss: 0.1492 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 66/200\n",
      "411/411 [==============================] - 0s 288us/sample - loss: 0.1464 - acc: 0.9392 - fn: 10.0000 - fp: 15.0000 - tn: 223.0000 - tp: 163.0000 - precision: 0.9157 - recall: 0.9422 - val_loss: 0.1350 - val_acc: 0.9562 - val_fn: 2.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 56.0000 - val_precision: 0.9333 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 67/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1771 - acc: 0.9343 - fn: 16.0000 - fp: 11.0000 - tn: 227.0000 - tp: 157.0000 - precision: 0.9345 - recall: 0.9075 - val_loss: 0.1513 - val_acc: 0.9562 - val_fn: 3.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 55.0000 - val_precision: 0.9483 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 68/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1674 - acc: 0.9319 - fn: 12.0000 - fp: 16.0000 - tn: 222.0000 - tp: 161.0000 - precision: 0.9096 - recall: 0.9306 - val_loss: 0.1313 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 69/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.1503 - acc: 0.9392 - fn: 14.0000 - fp: 11.0000 - tn: 227.0000 - tp: 159.0000 - precision: 0.9353 - recall: 0.9191 - val_loss: 0.1963 - val_acc: 0.9416 - val_fn: 5.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 70/200\n",
      "411/411 [==============================] - 0s 270us/sample - loss: 0.2209 - acc: 0.9197 - fn: 15.0000 - fp: 18.0000 - tn: 220.0000 - tp: 158.0000 - precision: 0.8977 - recall: 0.9133 - val_loss: 0.1747 - val_acc: 0.9270 - val_fn: 7.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 51.0000 - val_precision: 0.9444 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 71/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1902 - acc: 0.9246 - fn: 17.0000 - fp: 14.0000 - tn: 224.0000 - tp: 156.0000 - precision: 0.9176 - recall: 0.9017 - val_loss: 0.1693 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 72/200\n",
      "411/411 [==============================] - 0s 238us/sample - loss: 0.2013 - acc: 0.9343 - fn: 15.0000 - fp: 12.0000 - tn: 226.0000 - tp: 158.0000 - precision: 0.9294 - recall: 0.9133 - val_loss: 0.1805 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 73/200\n",
      "411/411 [==============================] - 0s 254us/sample - loss: 0.2582 - acc: 0.8808 - fn: 38.0000 - fp: 11.0000 - tn: 227.0000 - tp: 135.0000 - precision: 0.9247 - recall: 0.7803 - val_loss: 0.1779 - val_acc: 0.9270 - val_fn: 4.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 54.0000 - val_precision: 0.9000 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 74/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.2249 - acc: 0.9100 - fn: 21.0000 - fp: 16.0000 - tn: 222.0000 - tp: 152.0000 - precision: 0.9048 - recall: 0.8786 - val_loss: 0.1674 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 75/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.2086 - acc: 0.9173 - fn: 25.0000 - fp: 9.0000 - tn: 229.0000 - tp: 148.0000 - precision: 0.9427 - recall: 0.8555 - val_loss: 0.1954 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 76/200\n",
      "411/411 [==============================] - 0s 246us/sample - loss: 0.2239 - acc: 0.9075 - fn: 19.0000 - fp: 19.0000 - tn: 219.0000 - tp: 154.0000 - precision: 0.8902 - recall: 0.8902 - val_loss: 0.1736 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 77/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.1910 - acc: 0.9270 - fn: 16.0000 - fp: 14.0000 - tn: 224.0000 - tp: 157.0000 - precision: 0.9181 - recall: 0.9075 - val_loss: 0.1915 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 78/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1818 - acc: 0.9075 - fn: 20.0000 - fp: 18.0000 - tn: 220.0000 - tp: 153.0000 - precision: 0.8947 - recall: 0.8844 - val_loss: 0.1645 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 79/200\n",
      "411/411 [==============================] - 0s 265us/sample - loss: 0.1877 - acc: 0.9197 - fn: 17.0000 - fp: 16.0000 - tn: 222.0000 - tp: 156.0000 - precision: 0.9070 - recall: 0.9017 - val_loss: 0.2146 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 80/200\n",
      "411/411 [==============================] - 0s 265us/sample - loss: 0.1632 - acc: 0.9319 - fn: 12.0000 - fp: 16.0000 - tn: 222.0000 - tp: 161.0000 - precision: 0.9096 - recall: 0.9306 - val_loss: 0.1698 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 81/200\n",
      "411/411 [==============================] - 0s 254us/sample - loss: 0.1548 - acc: 0.9270 - fn: 12.0000 - fp: 18.0000 - tn: 220.0000 - tp: 161.0000 - precision: 0.8994 - recall: 0.9306 - val_loss: 0.1776 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 82/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.1668 - acc: 0.9319 - fn: 15.0000 - fp: 13.0000 - tn: 225.0000 - tp: 158.0000 - precision: 0.9240 - recall: 0.9133 - val_loss: 0.1570 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 83/200\n",
      "411/411 [==============================] - 0s 257us/sample - loss: 0.1551 - acc: 0.9294 - fn: 14.0000 - fp: 15.0000 - tn: 223.0000 - tp: 159.0000 - precision: 0.9138 - recall: 0.9191 - val_loss: 0.1409 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 84/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1642 - acc: 0.9270 - fn: 15.0000 - fp: 15.0000 - tn: 223.0000 - tp: 158.0000 - precision: 0.9133 - recall: 0.9133 - val_loss: 0.1743 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 85/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1377 - acc: 0.9392 - fn: 9.0000 - fp: 16.0000 - tn: 222.0000 - tp: 164.0000 - precision: 0.9111 - recall: 0.9480 - val_loss: 0.1746 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 86/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1571 - acc: 0.9343 - fn: 12.0000 - fp: 15.0000 - tn: 223.0000 - tp: 161.0000 - precision: 0.9148 - recall: 0.9306 - val_loss: 0.1892 - val_acc: 0.9489 - val_fn: 5.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 53.0000 - val_precision: 0.9636 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 87/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1695 - acc: 0.9173 - fn: 14.0000 - fp: 20.0000 - tn: 218.0000 - tp: 159.0000 - precision: 0.8883 - recall: 0.9191 - val_loss: 0.1658 - val_acc: 0.9635 - val_fn: 1.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 57.0000 - val_precision: 0.9344 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 88/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.1696 - acc: 0.9270 - fn: 16.0000 - fp: 14.0000 - tn: 224.0000 - tp: 157.0000 - precision: 0.9181 - recall: 0.9075 - val_loss: 0.1497 - val_acc: 0.9562 - val_fn: 3.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 55.0000 - val_precision: 0.9483 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 89/200\n",
      "411/411 [==============================] - 0s 255us/sample - loss: 0.1470 - acc: 0.9416 - fn: 10.0000 - fp: 14.0000 - tn: 224.0000 - tp: 163.0000 - precision: 0.9209 - recall: 0.9422 - val_loss: 0.1649 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 90/200\n",
      "411/411 [==============================] - 0s 255us/sample - loss: 0.1685 - acc: 0.9367 - fn: 16.0000 - fp: 10.0000 - tn: 228.0000 - tp: 157.0000 - precision: 0.9401 - recall: 0.9075 - val_loss: 0.1683 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 91/200\n",
      "411/411 [==============================] - 0s 259us/sample - loss: 0.2066 - acc: 0.9027 - fn: 20.0000 - fp: 20.0000 - tn: 218.0000 - tp: 153.0000 - precision: 0.8844 - recall: 0.8844 - val_loss: 0.1783 - val_acc: 0.9343 - val_fn: 6.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 52.0000 - val_precision: 0.9455 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 92/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1931 - acc: 0.9294 - fn: 21.0000 - fp: 8.0000 - tn: 230.0000 - tp: 152.0000 - precision: 0.9500 - recall: 0.8786 - val_loss: 0.1793 - val_acc: 0.9197 - val_fn: 7.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 51.0000 - val_precision: 0.9273 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 93/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1783 - acc: 0.9319 - fn: 14.0000 - fp: 14.0000 - tn: 224.0000 - tp: 159.0000 - precision: 0.9191 - recall: 0.9191 - val_loss: 0.1942 - val_acc: 0.9562 - val_fn: 4.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 54.0000 - val_precision: 0.9643 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 94/200\n",
      "411/411 [==============================] - 0s 282us/sample - loss: 0.1472 - acc: 0.9392 - fn: 16.0000 - fp: 9.0000 - tn: 229.0000 - tp: 157.0000 - precision: 0.9458 - recall: 0.9075 - val_loss: 0.2059 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 95/200\n",
      "411/411 [==============================] - 0s 262us/sample - loss: 0.1964 - acc: 0.9173 - fn: 17.0000 - fp: 17.0000 - tn: 221.0000 - tp: 156.0000 - precision: 0.9017 - recall: 0.9017 - val_loss: 0.2387 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 96/200\n",
      "411/411 [==============================] - 0s 278us/sample - loss: 0.1819 - acc: 0.9343 - fn: 15.0000 - fp: 12.0000 - tn: 226.0000 - tp: 158.0000 - precision: 0.9294 - recall: 0.9133 - val_loss: 0.2055 - val_acc: 0.9197 - val_fn: 3.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 55.0000 - val_precision: 0.8730 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 97/200\n",
      "411/411 [==============================] - 0s 275us/sample - loss: 0.1713 - acc: 0.9270 - fn: 10.0000 - fp: 20.0000 - tn: 218.0000 - tp: 163.0000 - precision: 0.8907 - recall: 0.9422 - val_loss: 0.2395 - val_acc: 0.9270 - val_fn: 7.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 51.0000 - val_precision: 0.9444 - val_recall: 0.8793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 98/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1449 - acc: 0.9416 - fn: 15.0000 - fp: 9.0000 - tn: 229.0000 - tp: 158.0000 - precision: 0.9461 - recall: 0.9133 - val_loss: 0.1763 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 99/200\n",
      "411/411 [==============================] - 0s 259us/sample - loss: 0.2537 - acc: 0.9246 - fn: 10.0000 - fp: 21.0000 - tn: 217.0000 - tp: 163.0000 - precision: 0.8859 - recall: 0.9422 - val_loss: 0.2321 - val_acc: 0.9270 - val_fn: 4.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 54.0000 - val_precision: 0.9000 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 100/200\n",
      "411/411 [==============================] - 0s 263us/sample - loss: 0.1806 - acc: 0.9246 - fn: 9.0000 - fp: 22.0000 - tn: 216.0000 - tp: 164.0000 - precision: 0.8817 - recall: 0.9480 - val_loss: 0.2423 - val_acc: 0.9343 - val_fn: 2.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 56.0000 - val_precision: 0.8889 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 101/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.2357 - acc: 0.9100 - fn: 11.0000 - fp: 26.0000 - tn: 212.0000 - tp: 162.0000 - precision: 0.8617 - recall: 0.9364 - val_loss: 0.1801 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 102/200\n",
      "411/411 [==============================] - 0s 260us/sample - loss: 0.2090 - acc: 0.9075 - fn: 16.0000 - fp: 22.0000 - tn: 216.0000 - tp: 157.0000 - precision: 0.8771 - recall: 0.9075 - val_loss: 0.2013 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 103/200\n",
      "411/411 [==============================] - 0s 283us/sample - loss: 0.1948 - acc: 0.9392 - fn: 10.0000 - fp: 15.0000 - tn: 223.0000 - tp: 163.0000 - precision: 0.9157 - recall: 0.9422 - val_loss: 0.2049 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 104/200\n",
      "411/411 [==============================] - 0s 252us/sample - loss: 0.1541 - acc: 0.9246 - fn: 15.0000 - fp: 16.0000 - tn: 222.0000 - tp: 158.0000 - precision: 0.9080 - recall: 0.9133 - val_loss: 0.1799 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 105/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1497 - acc: 0.9270 - fn: 17.0000 - fp: 13.0000 - tn: 225.0000 - tp: 156.0000 - precision: 0.9231 - recall: 0.9017 - val_loss: 0.1746 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 106/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.2056 - acc: 0.9319 - fn: 14.0000 - fp: 14.0000 - tn: 224.0000 - tp: 159.0000 - precision: 0.9191 - recall: 0.9191 - val_loss: 0.1974 - val_acc: 0.9343 - val_fn: 6.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 52.0000 - val_precision: 0.9455 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 107/200\n",
      "411/411 [==============================] - 0s 291us/sample - loss: 0.1820 - acc: 0.9343 - fn: 18.0000 - fp: 9.0000 - tn: 229.0000 - tp: 155.0000 - precision: 0.9451 - recall: 0.8960 - val_loss: 0.1795 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 108/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1781 - acc: 0.9270 - fn: 13.0000 - fp: 17.0000 - tn: 221.0000 - tp: 160.0000 - precision: 0.9040 - recall: 0.9249 - val_loss: 0.2473 - val_acc: 0.9197 - val_fn: 6.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 52.0000 - val_precision: 0.9123 - val_recall: 0.8966\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 109/200\n",
      "411/411 [==============================] - 0s 266us/sample - loss: 0.2007 - acc: 0.9173 - fn: 19.0000 - fp: 15.0000 - tn: 223.0000 - tp: 154.0000 - precision: 0.9112 - recall: 0.8902 - val_loss: 0.2711 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 110/200\n",
      "411/411 [==============================] - 0s 311us/sample - loss: 0.1656 - acc: 0.9246 - fn: 17.0000 - fp: 14.0000 - tn: 224.0000 - tp: 156.0000 - precision: 0.9176 - recall: 0.9017 - val_loss: 0.2043 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 111/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.2128 - acc: 0.9294 - fn: 13.0000 - fp: 16.0000 - tn: 222.0000 - tp: 160.0000 - precision: 0.9091 - recall: 0.9249 - val_loss: 0.3072 - val_acc: 0.9051 - val_fn: 1.0000 - val_fp: 12.0000 - val_tn: 67.0000 - val_tp: 57.0000 - val_precision: 0.8261 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 112/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.2111 - acc: 0.9051 - fn: 12.0000 - fp: 27.0000 - tn: 211.0000 - tp: 161.0000 - precision: 0.8564 - recall: 0.9306 - val_loss: 0.2984 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 113/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1848 - acc: 0.9173 - fn: 15.0000 - fp: 19.0000 - tn: 219.0000 - tp: 158.0000 - precision: 0.8927 - recall: 0.9133 - val_loss: 0.2101 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 114/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1788 - acc: 0.9343 - fn: 10.0000 - fp: 17.0000 - tn: 221.0000 - tp: 163.0000 - precision: 0.9056 - recall: 0.9422 - val_loss: 0.1796 - val_acc: 0.9197 - val_fn: 5.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 53.0000 - val_precision: 0.8983 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 115/200\n",
      "411/411 [==============================] - 0s 273us/sample - loss: 0.1959 - acc: 0.9270 - fn: 13.0000 - fp: 17.0000 - tn: 221.0000 - tp: 160.0000 - precision: 0.9040 - recall: 0.9249 - val_loss: 0.1911 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 116/200\n",
      "411/411 [==============================] - 0s 261us/sample - loss: 0.1475 - acc: 0.9367 - fn: 11.0000 - fp: 15.0000 - tn: 223.0000 - tp: 162.0000 - precision: 0.9153 - recall: 0.9364 - val_loss: 0.2283 - val_acc: 0.9416 - val_fn: 5.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 117/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1705 - acc: 0.9343 - fn: 14.0000 - fp: 13.0000 - tn: 225.0000 - tp: 159.0000 - precision: 0.9244 - recall: 0.9191 - val_loss: 0.1719 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 118/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1428 - acc: 0.9465 - fn: 11.0000 - fp: 11.0000 - tn: 227.0000 - tp: 162.0000 - precision: 0.9364 - recall: 0.9364 - val_loss: 0.2102 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 119/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1580 - acc: 0.9416 - fn: 10.0000 - fp: 14.0000 - tn: 224.0000 - tp: 163.0000 - precision: 0.9209 - recall: 0.9422 - val_loss: 0.1826 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 120/200\n",
      "411/411 [==============================] - 0s 277us/sample - loss: 0.1385 - acc: 0.9465 - fn: 11.0000 - fp: 11.0000 - tn: 227.0000 - tp: 162.0000 - precision: 0.9364 - recall: 0.9364 - val_loss: 0.1765 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 121/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1370 - acc: 0.9392 - fn: 12.0000 - fp: 13.0000 - tn: 225.0000 - tp: 161.0000 - precision: 0.9253 - recall: 0.9306 - val_loss: 0.1816 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 122/200\n",
      "411/411 [==============================] - 0s 259us/sample - loss: 0.2172 - acc: 0.9148 - fn: 17.0000 - fp: 18.0000 - tn: 220.0000 - tp: 156.0000 - precision: 0.8966 - recall: 0.9017 - val_loss: 0.1938 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 123/200\n",
      "411/411 [==============================] - 0s 271us/sample - loss: 0.1600 - acc: 0.9538 - fn: 8.0000 - fp: 11.0000 - tn: 227.0000 - tp: 165.0000 - precision: 0.9375 - recall: 0.9538 - val_loss: 0.1751 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 124/200\n",
      "411/411 [==============================] - 0s 306us/sample - loss: 0.1668 - acc: 0.9416 - fn: 12.0000 - fp: 12.0000 - tn: 226.0000 - tp: 161.0000 - precision: 0.9306 - recall: 0.9306 - val_loss: 0.1978 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 125/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1756 - acc: 0.9173 - fn: 17.0000 - fp: 17.0000 - tn: 221.0000 - tp: 156.0000 - precision: 0.9017 - recall: 0.9017 - val_loss: 0.1874 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 126/200\n",
      "411/411 [==============================] - 0s 276us/sample - loss: 0.1459 - acc: 0.9392 - fn: 8.0000 - fp: 17.0000 - tn: 221.0000 - tp: 165.0000 - precision: 0.9066 - recall: 0.9538 - val_loss: 0.1866 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 127/200\n",
      "411/411 [==============================] - 0s 313us/sample - loss: 0.1413 - acc: 0.9489 - fn: 10.0000 - fp: 11.0000 - tn: 227.0000 - tp: 163.0000 - precision: 0.9368 - recall: 0.9422 - val_loss: 0.1627 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 128/200\n",
      "411/411 [==============================] - 0s 306us/sample - loss: 0.1235 - acc: 0.9440 - fn: 9.0000 - fp: 14.0000 - tn: 224.0000 - tp: 164.0000 - precision: 0.9213 - recall: 0.9480 - val_loss: 0.1993 - val_acc: 0.9562 - val_fn: 3.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 55.0000 - val_precision: 0.9483 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 129/200\n",
      "411/411 [==============================] - 0s 271us/sample - loss: 0.1387 - acc: 0.9367 - fn: 8.0000 - fp: 18.0000 - tn: 220.0000 - tp: 165.0000 - precision: 0.9016 - recall: 0.9538 - val_loss: 0.1961 - val_acc: 0.9562 - val_fn: 3.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 55.0000 - val_precision: 0.9483 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 130/200\n",
      "411/411 [==============================] - 0s 268us/sample - loss: 0.1721 - acc: 0.9294 - fn: 14.0000 - fp: 15.0000 - tn: 223.0000 - tp: 159.0000 - precision: 0.9138 - recall: 0.9191 - val_loss: 0.1816 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 131/200\n",
      "411/411 [==============================] - 0s 277us/sample - loss: 0.1489 - acc: 0.9440 - fn: 10.0000 - fp: 13.0000 - tn: 225.0000 - tp: 163.0000 - precision: 0.9261 - recall: 0.9422 - val_loss: 0.2378 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 132/200\n",
      "411/411 [==============================] - 0s 267us/sample - loss: 0.1955 - acc: 0.9294 - fn: 9.0000 - fp: 20.0000 - tn: 218.0000 - tp: 164.0000 - precision: 0.8913 - recall: 0.9480 - val_loss: 0.2964 - val_acc: 0.9270 - val_fn: 5.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 53.0000 - val_precision: 0.9138 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 133/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.2323 - acc: 0.9221 - fn: 15.0000 - fp: 17.0000 - tn: 221.0000 - tp: 158.0000 - precision: 0.9029 - recall: 0.9133 - val_loss: 0.1564 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 134/200\n",
      "411/411 [==============================] - 0s 260us/sample - loss: 0.1893 - acc: 0.9124 - fn: 13.0000 - fp: 23.0000 - tn: 215.0000 - tp: 160.0000 - precision: 0.8743 - recall: 0.9249 - val_loss: 0.2247 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 135/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1630 - acc: 0.9221 - fn: 12.0000 - fp: 20.0000 - tn: 218.0000 - tp: 161.0000 - precision: 0.8895 - recall: 0.9306 - val_loss: 0.1941 - val_acc: 0.9197 - val_fn: 3.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 55.0000 - val_precision: 0.8730 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 136/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.1911 - acc: 0.9051 - fn: 6.0000 - fp: 33.0000 - tn: 205.0000 - tp: 167.0000 - precision: 0.8350 - recall: 0.9653 - val_loss: 0.1711 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 137/200\n",
      "411/411 [==============================] - 0s 258us/sample - loss: 0.1835 - acc: 0.9416 - fn: 11.0000 - fp: 13.0000 - tn: 225.0000 - tp: 162.0000 - precision: 0.9257 - recall: 0.9364 - val_loss: 0.1520 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 138/200\n",
      "411/411 [==============================] - 0s 260us/sample - loss: 0.1436 - acc: 0.9489 - fn: 10.0000 - fp: 11.0000 - tn: 227.0000 - tp: 163.0000 - precision: 0.9368 - recall: 0.9422 - val_loss: 0.1495 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 139/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.1435 - acc: 0.9465 - fn: 13.0000 - fp: 9.0000 - tn: 229.0000 - tp: 160.0000 - precision: 0.9467 - recall: 0.9249 - val_loss: 0.1442 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 140/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1371 - acc: 0.9489 - fn: 9.0000 - fp: 12.0000 - tn: 226.0000 - tp: 164.0000 - precision: 0.9318 - recall: 0.9480 - val_loss: 0.1433 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 141/200\n",
      "411/411 [==============================] - 0s 252us/sample - loss: 0.1511 - acc: 0.9416 - fn: 11.0000 - fp: 13.0000 - tn: 225.0000 - tp: 162.0000 - precision: 0.9257 - recall: 0.9364 - val_loss: 0.1308 - val_acc: 0.9416 - val_fn: 5.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 142/200\n",
      "411/411 [==============================] - 0s 255us/sample - loss: 0.1262 - acc: 0.9538 - fn: 10.0000 - fp: 9.0000 - tn: 229.0000 - tp: 163.0000 - precision: 0.9477 - recall: 0.9422 - val_loss: 0.1543 - val_acc: 0.9562 - val_fn: 1.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 57.0000 - val_precision: 0.9194 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 143/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1312 - acc: 0.9465 - fn: 11.0000 - fp: 11.0000 - tn: 227.0000 - tp: 162.0000 - precision: 0.9364 - recall: 0.9364 - val_loss: 0.1409 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 144/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1263 - acc: 0.9465 - fn: 8.0000 - fp: 14.0000 - tn: 224.0000 - tp: 165.0000 - precision: 0.9218 - recall: 0.9538 - val_loss: 0.1744 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 145/200\n",
      "411/411 [==============================] - 0s 264us/sample - loss: 0.1123 - acc: 0.9513 - fn: 9.0000 - fp: 11.0000 - tn: 227.0000 - tp: 164.0000 - precision: 0.9371 - recall: 0.9480 - val_loss: 0.1616 - val_acc: 0.9635 - val_fn: 2.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 56.0000 - val_precision: 0.9492 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 146/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1234 - acc: 0.9538 - fn: 9.0000 - fp: 10.0000 - tn: 228.0000 - tp: 164.0000 - precision: 0.9425 - recall: 0.9480 - val_loss: 0.1606 - val_acc: 0.9635 - val_fn: 3.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 55.0000 - val_precision: 0.9649 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 147/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1474 - acc: 0.9440 - fn: 12.0000 - fp: 11.0000 - tn: 227.0000 - tp: 161.0000 - precision: 0.9360 - recall: 0.9306 - val_loss: 0.1582 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 148/200\n",
      "411/411 [==============================] - 0s 246us/sample - loss: 0.1380 - acc: 0.9440 - fn: 6.0000 - fp: 17.0000 - tn: 221.0000 - tp: 167.0000 - precision: 0.9076 - recall: 0.9653 - val_loss: 0.2330 - val_acc: 0.9416 - val_fn: 5.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 149/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1153 - acc: 0.9513 - fn: 10.0000 - fp: 10.0000 - tn: 228.0000 - tp: 163.0000 - precision: 0.9422 - recall: 0.9422 - val_loss: 0.1951 - val_acc: 0.9416 - val_fn: 5.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 150/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1362 - acc: 0.9392 - fn: 11.0000 - fp: 14.0000 - tn: 224.0000 - tp: 162.0000 - precision: 0.9205 - recall: 0.9364 - val_loss: 0.1543 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 151/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.2227 - acc: 0.8905 - fn: 14.0000 - fp: 31.0000 - tn: 207.0000 - tp: 159.0000 - precision: 0.8368 - recall: 0.9191 - val_loss: 0.2146 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 152/200\n",
      "411/411 [==============================] - 0s 261us/sample - loss: 0.1497 - acc: 0.9343 - fn: 11.0000 - fp: 16.0000 - tn: 222.0000 - tp: 162.0000 - precision: 0.9101 - recall: 0.9364 - val_loss: 0.2506 - val_acc: 0.9343 - val_fn: 4.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 54.0000 - val_precision: 0.9153 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 153/200\n",
      "411/411 [==============================] - 0s 260us/sample - loss: 0.1564 - acc: 0.9440 - fn: 13.0000 - fp: 10.0000 - tn: 228.0000 - tp: 160.0000 - precision: 0.9412 - recall: 0.9249 - val_loss: 0.2453 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 154/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1508 - acc: 0.9440 - fn: 13.0000 - fp: 10.0000 - tn: 228.0000 - tp: 160.0000 - precision: 0.9412 - recall: 0.9249 - val_loss: 0.2268 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 155/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1802 - acc: 0.9294 - fn: 12.0000 - fp: 17.0000 - tn: 221.0000 - tp: 161.0000 - precision: 0.9045 - recall: 0.9306 - val_loss: 0.2291 - val_acc: 0.9197 - val_fn: 4.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 54.0000 - val_precision: 0.8852 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 156/200\n",
      "411/411 [==============================] - 0s 259us/sample - loss: 0.2467 - acc: 0.9246 - fn: 14.0000 - fp: 17.0000 - tn: 221.0000 - tp: 159.0000 - precision: 0.9034 - recall: 0.9191 - val_loss: 0.1997 - val_acc: 0.9343 - val_fn: 2.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 56.0000 - val_precision: 0.8889 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 157/200\n",
      "411/411 [==============================] - 0s 283us/sample - loss: 0.1572 - acc: 0.9343 - fn: 12.0000 - fp: 15.0000 - tn: 223.0000 - tp: 161.0000 - precision: 0.9148 - recall: 0.9306 - val_loss: 0.2104 - val_acc: 0.9197 - val_fn: 3.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 55.0000 - val_precision: 0.8730 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 158/200\n",
      "411/411 [==============================] - 0s 321us/sample - loss: 0.1356 - acc: 0.9513 - fn: 9.0000 - fp: 11.0000 - tn: 227.0000 - tp: 164.0000 - precision: 0.9371 - recall: 0.9480 - val_loss: 0.1880 - val_acc: 0.9416 - val_fn: 2.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 159/200\n",
      "411/411 [==============================] - 0s 297us/sample - loss: 0.2032 - acc: 0.9148 - fn: 12.0000 - fp: 23.0000 - tn: 215.0000 - tp: 161.0000 - precision: 0.8750 - recall: 0.9306 - val_loss: 0.1678 - val_acc: 0.9343 - val_fn: 2.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 56.0000 - val_precision: 0.8889 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 160/200\n",
      "411/411 [==============================] - 0s 291us/sample - loss: 0.1497 - acc: 0.9416 - fn: 9.0000 - fp: 15.0000 - tn: 223.0000 - tp: 164.0000 - precision: 0.9162 - recall: 0.9480 - val_loss: 0.1626 - val_acc: 0.9416 - val_fn: 2.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 161/200\n",
      "411/411 [==============================] - 0s 302us/sample - loss: 0.1522 - acc: 0.9392 - fn: 8.0000 - fp: 17.0000 - tn: 221.0000 - tp: 165.0000 - precision: 0.9066 - recall: 0.9538 - val_loss: 0.1993 - val_acc: 0.9416 - val_fn: 2.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 162/200\n",
      "411/411 [==============================] - 0s 260us/sample - loss: 0.1449 - acc: 0.9538 - fn: 11.0000 - fp: 8.0000 - tn: 230.0000 - tp: 162.0000 - precision: 0.9529 - recall: 0.9364 - val_loss: 0.1850 - val_acc: 0.9124 - val_fn: 2.0000 - val_fp: 10.0000 - val_tn: 69.0000 - val_tp: 56.0000 - val_precision: 0.8485 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 163/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1460 - acc: 0.9440 - fn: 7.0000 - fp: 16.0000 - tn: 222.0000 - tp: 166.0000 - precision: 0.9121 - recall: 0.9595 - val_loss: 0.2032 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 164/200\n",
      "411/411 [==============================] - 0s 250us/sample - loss: 0.1625 - acc: 0.9440 - fn: 12.0000 - fp: 11.0000 - tn: 227.0000 - tp: 161.0000 - precision: 0.9360 - recall: 0.9306 - val_loss: 0.1782 - val_acc: 0.9416 - val_fn: 2.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 165/200\n",
      "411/411 [==============================] - 0s 246us/sample - loss: 0.1347 - acc: 0.9440 - fn: 12.0000 - fp: 11.0000 - tn: 227.0000 - tp: 161.0000 - precision: 0.9360 - recall: 0.9306 - val_loss: 0.2368 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 166/200\n",
      "411/411 [==============================] - 0s 246us/sample - loss: 0.1363 - acc: 0.9489 - fn: 8.0000 - fp: 13.0000 - tn: 225.0000 - tp: 165.0000 - precision: 0.9270 - recall: 0.9538 - val_loss: 0.2167 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 167/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.1208 - acc: 0.9440 - fn: 11.0000 - fp: 12.0000 - tn: 226.0000 - tp: 162.0000 - precision: 0.9310 - recall: 0.9364 - val_loss: 0.2331 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 168/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1465 - acc: 0.9294 - fn: 12.0000 - fp: 17.0000 - tn: 221.0000 - tp: 161.0000 - precision: 0.9045 - recall: 0.9306 - val_loss: 0.2023 - val_acc: 0.9562 - val_fn: 2.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 56.0000 - val_precision: 0.9333 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 169/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.1306 - acc: 0.9586 - fn: 10.0000 - fp: 7.0000 - tn: 231.0000 - tp: 163.0000 - precision: 0.9588 - recall: 0.9422 - val_loss: 0.2043 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 170/200\n",
      "411/411 [==============================] - 0s 253us/sample - loss: 0.1272 - acc: 0.9489 - fn: 9.0000 - fp: 12.0000 - tn: 226.0000 - tp: 164.0000 - precision: 0.9318 - recall: 0.9480 - val_loss: 0.2194 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 171/200\n",
      "411/411 [==============================] - 0s 261us/sample - loss: 0.1242 - acc: 0.9489 - fn: 11.0000 - fp: 10.0000 - tn: 228.0000 - tp: 162.0000 - precision: 0.9419 - recall: 0.9364 - val_loss: 0.2116 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 172/200\n",
      "411/411 [==============================] - 0s 252us/sample - loss: 0.0989 - acc: 0.9513 - fn: 10.0000 - fp: 10.0000 - tn: 228.0000 - tp: 163.0000 - precision: 0.9422 - recall: 0.9422 - val_loss: 0.2394 - val_acc: 0.9416 - val_fn: 2.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 173/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.1486 - acc: 0.9465 - fn: 13.0000 - fp: 9.0000 - tn: 229.0000 - tp: 160.0000 - precision: 0.9467 - recall: 0.9249 - val_loss: 0.2778 - val_acc: 0.9343 - val_fn: 1.0000 - val_fp: 8.0000 - val_tn: 71.0000 - val_tp: 57.0000 - val_precision: 0.8769 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 174/200\n",
      "411/411 [==============================] - 0s 238us/sample - loss: 0.3152 - acc: 0.9173 - fn: 15.0000 - fp: 19.0000 - tn: 219.0000 - tp: 158.0000 - precision: 0.8927 - recall: 0.9133 - val_loss: 0.1578 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 175/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.1860 - acc: 0.9197 - fn: 16.0000 - fp: 17.0000 - tn: 221.0000 - tp: 157.0000 - precision: 0.9023 - recall: 0.9075 - val_loss: 0.2276 - val_acc: 0.9197 - val_fn: 2.0000 - val_fp: 9.0000 - val_tn: 70.0000 - val_tp: 56.0000 - val_precision: 0.8615 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 176/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.2136 - acc: 0.9051 - fn: 11.0000 - fp: 28.0000 - tn: 210.0000 - tp: 162.0000 - precision: 0.8526 - recall: 0.9364 - val_loss: 0.2178 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 177/200\n",
      "411/411 [==============================] - 0s 266us/sample - loss: 0.1674 - acc: 0.9319 - fn: 9.0000 - fp: 19.0000 - tn: 219.0000 - tp: 164.0000 - precision: 0.8962 - recall: 0.9480 - val_loss: 0.1703 - val_acc: 0.9489 - val_fn: 4.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 54.0000 - val_precision: 0.9474 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 178/200\n",
      "411/411 [==============================] - 0s 256us/sample - loss: 0.1500 - acc: 0.9367 - fn: 14.0000 - fp: 12.0000 - tn: 226.0000 - tp: 159.0000 - precision: 0.9298 - recall: 0.9191 - val_loss: 0.1610 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 179/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.1380 - acc: 0.9440 - fn: 10.0000 - fp: 13.0000 - tn: 225.0000 - tp: 163.0000 - precision: 0.9261 - recall: 0.9422 - val_loss: 0.1818 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 180/200\n",
      "411/411 [==============================] - 0s 272us/sample - loss: 0.1318 - acc: 0.9465 - fn: 12.0000 - fp: 10.0000 - tn: 228.0000 - tp: 161.0000 - precision: 0.9415 - recall: 0.9306 - val_loss: 0.1899 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 181/200\n",
      "411/411 [==============================] - 0s 265us/sample - loss: 0.1694 - acc: 0.9392 - fn: 9.0000 - fp: 16.0000 - tn: 222.0000 - tp: 164.0000 - precision: 0.9111 - recall: 0.9480 - val_loss: 0.1550 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 182/200\n",
      "411/411 [==============================] - 0s 242us/sample - loss: 0.1189 - acc: 0.9489 - fn: 9.0000 - fp: 12.0000 - tn: 226.0000 - tp: 164.0000 - precision: 0.9318 - recall: 0.9480 - val_loss: 0.1790 - val_acc: 0.9562 - val_fn: 3.0000 - val_fp: 3.0000 - val_tn: 76.0000 - val_tp: 55.0000 - val_precision: 0.9483 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 183/200\n",
      "411/411 [==============================] - 0s 251us/sample - loss: 0.1166 - acc: 0.9562 - fn: 9.0000 - fp: 9.0000 - tn: 229.0000 - tp: 164.0000 - precision: 0.9480 - recall: 0.9480 - val_loss: 0.1956 - val_acc: 0.9489 - val_fn: 2.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 56.0000 - val_precision: 0.9180 - val_recall: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 184/200\n",
      "411/411 [==============================] - 0s 254us/sample - loss: 0.1129 - acc: 0.9465 - fn: 11.0000 - fp: 11.0000 - tn: 227.0000 - tp: 162.0000 - precision: 0.9364 - recall: 0.9364 - val_loss: 0.2055 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 185/200\n",
      "411/411 [==============================] - 0s 249us/sample - loss: 0.1767 - acc: 0.9367 - fn: 8.0000 - fp: 18.0000 - tn: 220.0000 - tp: 165.0000 - precision: 0.9016 - recall: 0.9538 - val_loss: 0.1773 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 186/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1478 - acc: 0.9465 - fn: 13.0000 - fp: 9.0000 - tn: 229.0000 - tp: 160.0000 - precision: 0.9467 - recall: 0.9249 - val_loss: 0.2735 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 187/200\n",
      "411/411 [==============================] - 0s 245us/sample - loss: 0.1526 - acc: 0.9392 - fn: 9.0000 - fp: 16.0000 - tn: 222.0000 - tp: 164.0000 - precision: 0.9111 - recall: 0.9480 - val_loss: 0.2949 - val_acc: 0.9270 - val_fn: 3.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 55.0000 - val_precision: 0.8871 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 188/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1350 - acc: 0.9343 - fn: 10.0000 - fp: 17.0000 - tn: 221.0000 - tp: 163.0000 - precision: 0.9056 - recall: 0.9422 - val_loss: 0.2455 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 189/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.1082 - acc: 0.9538 - fn: 7.0000 - fp: 12.0000 - tn: 226.0000 - tp: 166.0000 - precision: 0.9326 - recall: 0.9595 - val_loss: 0.2391 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 190/200\n",
      "411/411 [==============================] - 0s 247us/sample - loss: 0.0975 - acc: 0.9538 - fn: 9.0000 - fp: 10.0000 - tn: 228.0000 - tp: 164.0000 - precision: 0.9425 - recall: 0.9480 - val_loss: 0.2629 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 191/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1159 - acc: 0.9465 - fn: 9.0000 - fp: 13.0000 - tn: 225.0000 - tp: 164.0000 - precision: 0.9266 - recall: 0.9480 - val_loss: 0.2824 - val_acc: 0.9343 - val_fn: 3.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 192/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1418 - acc: 0.9538 - fn: 9.0000 - fp: 10.0000 - tn: 228.0000 - tp: 164.0000 - precision: 0.9425 - recall: 0.9480 - val_loss: 0.3642 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 193/200\n",
      "411/411 [==============================] - 0s 243us/sample - loss: 0.1897 - acc: 0.9197 - fn: 11.0000 - fp: 22.0000 - tn: 216.0000 - tp: 162.0000 - precision: 0.8804 - recall: 0.9364 - val_loss: 0.2549 - val_acc: 0.9416 - val_fn: 4.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 194/200\n",
      "411/411 [==============================] - 0s 244us/sample - loss: 0.1455 - acc: 0.9270 - fn: 12.0000 - fp: 18.0000 - tn: 220.0000 - tp: 161.0000 - precision: 0.8994 - recall: 0.9306 - val_loss: 0.3060 - val_acc: 0.9416 - val_fn: 3.0000 - val_fp: 5.0000 - val_tn: 74.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 195/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1400 - acc: 0.9343 - fn: 6.0000 - fp: 21.0000 - tn: 217.0000 - tp: 167.0000 - precision: 0.8883 - recall: 0.9653 - val_loss: 0.2790 - val_acc: 0.9343 - val_fn: 5.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 53.0000 - val_precision: 0.9298 - val_recall: 0.9138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 196/200\n",
      "411/411 [==============================] - 0s 241us/sample - loss: 0.1994 - acc: 0.9173 - fn: 19.0000 - fp: 15.0000 - tn: 223.0000 - tp: 154.0000 - precision: 0.9112 - recall: 0.8902 - val_loss: 0.2263 - val_acc: 0.9416 - val_fn: 1.0000 - val_fp: 7.0000 - val_tn: 72.0000 - val_tp: 57.0000 - val_precision: 0.8906 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 197/200\n",
      "411/411 [==============================] - 0s 261us/sample - loss: 0.1930 - acc: 0.9270 - fn: 16.0000 - fp: 14.0000 - tn: 224.0000 - tp: 157.0000 - precision: 0.9181 - recall: 0.9075 - val_loss: 0.1664 - val_acc: 0.9635 - val_fn: 3.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 55.0000 - val_precision: 0.9649 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 198/200\n",
      "411/411 [==============================] - 0s 262us/sample - loss: 0.1931 - acc: 0.9319 - fn: 12.0000 - fp: 16.0000 - tn: 222.0000 - tp: 161.0000 - precision: 0.9096 - recall: 0.9306 - val_loss: 0.2104 - val_acc: 0.9489 - val_fn: 1.0000 - val_fp: 6.0000 - val_tn: 73.0000 - val_tp: 57.0000 - val_precision: 0.9048 - val_recall: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 199/200\n",
      "411/411 [==============================] - 0s 248us/sample - loss: 0.1534 - acc: 0.9343 - fn: 9.0000 - fp: 18.0000 - tn: 220.0000 - tp: 164.0000 - precision: 0.9011 - recall: 0.9480 - val_loss: 0.2567 - val_acc: 0.9489 - val_fn: 3.0000 - val_fp: 4.0000 - val_tn: 75.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.9483\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 200/200\n",
      "411/411 [==============================] - 0s 246us/sample - loss: 0.1532 - acc: 0.9294 - fn: 13.0000 - fp: 16.0000 - tn: 222.0000 - tp: 160.0000 - precision: 0.9091 - recall: 0.9249 - val_loss: 0.1906 - val_acc: 0.9562 - val_fn: 4.0000 - val_fp: 2.0000 - val_tn: 77.0000 - val_tp: 54.0000 - val_precision: 0.9643 - val_recall: 0.9310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    'accuracy',\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "\n",
    "\n",
    "history=model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=10,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, y_test),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'fn', 'fp', 'tn', 'tp', 'precision', 'recall', 'val_loss', 'val_acc', 'val_fn', 'val_fp', 'val_tn', 'val_tp', 'val_precision', 'val_recall'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-4267b39aca91>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# summarize history for accuracy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'model accuracy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.956\n",
      "Recall:  0.931\n",
      "Precision:  0.964\n",
      "ROC AUC:  0.953\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, model.predict_classes(X_test)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "recall = round(recall_score(y_true, y_pred),3)\n",
    "precision = round(precision_score(y_true, y_pred),3)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred),3)\n",
    "\n",
    "print('Accuracy: ',accuracy)\n",
    "print('Recall: ',recall)\n",
    "print('Precision: ',precision)\n",
    "print('ROC AUC: ',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}